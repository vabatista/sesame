{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/U4VN/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/U4VN/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import openai\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import RawVectorQuery\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Replace these with your service-specific values, make sure you give your user access to use these resources, or use keys for auth\n",
    "#AZURE_OPENAI_URL = \"<<your openai service url>>\" # your Azure OpenAI instance\n",
    "AZURE_SEARCH_SERVICE = \"\"\n",
    "AZURE_SEARCH_APIKEY = \"\"\n",
    "\n",
    "creds = AzureKeyCredential(AZURE_SEARCH_APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "def cosine_similarity(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projetos/u4vn/.venv/sbert-azure/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/projetos/u4vn/.venv/sbert-azure/lib64/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document similarity modeled as cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The dog plays in the garden \t\t Score: 0.08427257835865021\n",
      "The new movie is awesome \t\t This recent movie is so good \t\t Score: 0.6956300139427185\n",
      "The new movie is awesome \t\t The new movie is awesome \t\t Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "sentences1 = ['The new movie is awesome',\n",
    "             'The new movie is awesome',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'This recent movie is so good',\n",
    "              'The new movie is awesome']\n",
    "\n",
    "embeddings1 = [model.encode(s) for s in sentences1]\n",
    "embeddings2 = [model.encode(s) for s in sentences2]\n",
    "\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {}\".format(sentences1[i], sentences2[i], util.cos_sim(embeddings1[i], embeddings2[i])[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_squad_dataset(input_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        json_list = list(file)\n",
    "\n",
    "    data = []\n",
    "    # [1:] removes the header\n",
    "    for item in json_list[1:]:\n",
    "        item = json.loads(item)\n",
    "        data.append(item)\n",
    "    return data\n",
    "\n",
    "def get_contexts_questions(squad_data):\n",
    "    sentences = []\n",
    "    questions = []\n",
    "    q2s = {}\n",
    "    last_sent_idx = 0\n",
    "    cur_q_idx = -1\n",
    "    for data in squad_data:\n",
    "        last_sent_idx = len(sentences)\n",
    "        context = data['context']\n",
    "        context_sentences = sent_tokenize(context)\n",
    "        sentences.extend(context_sentences)\n",
    "\n",
    "        for qa in data['qas']:\n",
    "            question = qa['question']\n",
    "\n",
    "            answer_starts = [start[0] for start in qa['detected_answers'][0]['char_spans']]\n",
    "            #answer_text = qa['detected_answers'][0]['text']\n",
    "            cur_q_idx += 1\n",
    "            questions.append(question)\n",
    "            q2s[cur_q_idx] = []\n",
    "\n",
    "            # Find the sentence containing the answer span\n",
    "            for idx, s in enumerate(context_sentences):\n",
    "                start_index = context.find(s)\n",
    "                end_index = start_index + len(s)\n",
    "                for answer_start in answer_starts:\n",
    "                    if start_index <= answer_start < end_index:\n",
    "                        q2s[cur_q_idx].append(idx + last_sent_idx)\n",
    "\n",
    "    return sentences, questions, q2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n",
      "2514 1503 1503\n"
     ]
    }
   ],
   "source": [
    "squad_data = load_squad_dataset('./DROP-dev.jsonl')\n",
    "print(len(squad_data))\n",
    "sentences, questions, q2s = get_contexts_questions(squad_data)\n",
    "print(len(sentences), len(questions), len(q2s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AZURE_SEARCH_INDEX = \"dropqa\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes.models._index.SearchIndex at 0x2b5b47fe7490>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=AZURE_SEARCH_INDEX, \n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchField(name=\"content\", type=SearchFieldDataType.String),\n",
    "        SearchField(name=\"embedding\", \n",
    "                    type=SearchFieldDataType.Collection(SearchFieldDataType.Single), \n",
    "                    searchable=True, \n",
    "                    vector_search_dimensions=EMB_SIZE,\n",
    "                    vector_search_profile=\"vprofile\")\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[HnswVectorSearchAlgorithmConfiguration(name=\"algo\", parameters=HnswParameters(metric=\"cosine\"))],\n",
    "        profiles=[VectorSearchProfile(name=\"vprofile\", algorithm=\"algo\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(AZURE_SEARCH_SERVICE, credential=creds)\n",
    "index_client.create_index(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sesame.search.windows.net dropqa\n"
     ]
    }
   ],
   "source": [
    "print(AZURE_SEARCH_SERVICE, AZURE_SEARCH_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_client = SearchClient(AZURE_SEARCH_SERVICE, AZURE_SEARCH_INDEX, credential=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1955/1955 [28:38<00:00,  1.14it/s] \n"
     ]
    }
   ],
   "source": [
    "embs = model.encode(sentences, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = [{\"id\": str(i), \"embedding\": embs[i].tolist(), \"content\": s} for i,s in enumerate(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 1000\n",
    "doc_batches = [docs[i:i+batch_size] for i in range(0, len(docs), batch_size)]\n",
    "\n",
    "# Upload documents in batches\n",
    "for batch in doc_batches:\n",
    "    _ = search_client.upload_documents(documents=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing finished\n"
     ]
    }
   ],
   "source": [
    "print('Indexing finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search using vector similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid + Semantic Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which mobile phone operator has more users, Mtel or Vivacom?\n",
      "\n",
      "id: 148, Currently there are three active mobile phone operators—Mobiltel, Telenor and Vivacom, Mtel is the largest one with 5.2 million users as of 2010, Telenor has 3,9 million as of 2007 and Vivacom over 1 million., score: 0.03333333507180214, reranker: 3.6415441036224365\n",
      "id: 2047, This is compared with 859.9 in 2008 and 964.7 in 1990., score: 0.012345679104328156, reranker: 0.9217217564582825\n",
      "id: 1053, The population density was ., score: 0.012048192322254181, reranker: 0.515778124332428\n",
      "id: 2057, Privatization of the state-owned telecommunications firm Český Telecom took place in 2005., score: 0.014492753893136978, reranker: 0.24234060943126678\n",
      "id: 1817, Chinese in Spain number over 166,000., score: 0.013333333656191826, reranker: 0.18412983417510986\n"
     ]
    }
   ],
   "source": [
    "idx = 111\n",
    "q = questions[idx]\n",
    "print(f'Question: {q}')\n",
    "#print(f'Correct Sentence: {sentences[q2s[idx]]}')\n",
    "print()\n",
    "r = search_client.search(q, top=5, \n",
    "                         vector_queries=[RawVectorQuery(vector=model.encode(q), k=50, fields=\"embedding\")],\n",
    "                         query_type=\"semantic\", semantic_configuration_name=\"default\", query_language=\"en-us\")\n",
    "for doc in r:\n",
    "    print(f\"id: {doc['id']}, {doc['content']}, score: {doc['@search.score']}, reranker: {doc['@search.reranker_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP_K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 891/1503 [04:42<03:04,  3.31it/s]"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "reciprocal_ranks = []\n",
    "MAX_CONCURRENT_TASKS = 8\n",
    "\n",
    "def process_question(question, idx, q2s, model, search_client):\n",
    "    question_embedding = model.encode(question, show_progress_bar=False)\n",
    "    idx_correct = q2s[idx]\n",
    "    if idx_correct is None:\n",
    "        return None\n",
    "\n",
    "    results = search_client.search(question, top=TOP_K, \n",
    "                                   vector_queries=[RawVectorQuery(vector=question_embedding, k=50, fields=\"embedding\")],\n",
    "                                   query_type=\"semantic\", semantic_configuration_name=\"default\", query_language=\"en-us\")\n",
    "\n",
    "    for rank, hit in enumerate(results):\n",
    "        if int(hit['id']) in idx_correct:\n",
    "            return 1/(rank+1)\n",
    "    return 0.0\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_CONCURRENT_TASKS) as executor:\n",
    "    futures = [executor.submit(process_question, question, idx, q2s, model, search_client) for idx, question in enumerate(questions)]\n",
    "\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures), total=len(questions)):\n",
    "        if future.result() is not None:\n",
    "            reciprocal_ranks.append(future.result())\n",
    "\n",
    "print(f'MRR@{TOP_K} for {AZURE_SEARCH_INDEX} = {np.mean(reciprocal_ranks)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sbert-azure",
   "language": "python",
   "name": "sbert-azure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
